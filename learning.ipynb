{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selfscrum/hello-ai/blob/main/learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjbM5InfQjTM"
      },
      "source": [
        "# Setting up a Hosting Provider\n",
        "\n",
        "If you have worked with Cloud providers, you know the setup of virtual machines. While for classic projects, a virtual machine is rather a convenience (quick setup, automated installation, secured environment etc.), it becomes a \"must\" for experiments with AI. Models, data, and processing needs grow so quick that maintaining your own setup is not feasible any longer - at least until you leave learning mode and decide to build your own AI factory ðŸ˜….\n",
        "\n",
        "For first steps, [Google Colab](https://colab.research.google.com/) is a good and easy to use option:\n",
        "* Free for initial steps.\n",
        "* Integrated with your Google Account and Drive, so you have a project store already.\n",
        "* Integrated with Github, so you can easily maintain the development of your notebooks in an orderly fashion.\n",
        "* Paid upgrades possible if you need more.\n",
        "* Local runtime of Jupyter possible if you already have resources available ([Setup Info ](https://research.google.com/colaboratory/local-runtimes.html), not yet tried).\n",
        "\n",
        "Especially in the free environment, Colab has some performance and quality issues. You will learn pretty quick about broken tasks because your (virtual) hardware is not sufficient. So if you want to upgrade to Colab Pro or move to a more specialized provider, feel free to do so. I tried some few, but are not yet able to compare them systematically since I basically used only beginner's feature sets.\n",
        "\n",
        "* [RunPod](https://www.runpod.io/) - GPU Cloud with pre-setup environments\n",
        "* [Paperspace](https://paperspace.com) - Notebooks, GPU, Deployment Services\n",
        "* [HuggingFace](https://huggingface.co/) - Home of the Open Source Models, Development and Deployment ecosystem (you will need here an account in any case if you want to use one of the open models like Stable Diffusion or GPT-J).\n",
        "\n",
        "---\n",
        "> **Keep an eye on where you commit to usage fees, there are many tools out there that require a funding source. Even if it is only some cents for initial experiments, consumption can get out of hand easily.**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLk0C-xbWdn_"
      },
      "source": [
        "# Know Your Tools\n",
        "\n",
        "It's great that ChatGPT can write now software code for you, but what do you do with it? Today's tool chain maturity still requires that you integrate partial results into an end-to-end workstream. So you should at least roughly know what you are doing with the individual components.\n",
        "\n",
        "For developers this might be familiar turf to some extent, so you can quickly flip through this block. For everyone else, this chapter is not necessarily a roadblock before you can jump into AI joys, but it can't hurt to make yourself familiar with these concepts before or in parallel to the AI learning, depending how you learn best.\n",
        "\n",
        "## Git\n",
        "git is the central repository for developer articats and platforms like Github have evolved to a complete tech ecosystem. I don't want to write just another git manual, there is plenty out there. Checkout some places to learn about the basic lifecycle, this is enough for our purposes.\n",
        "\n",
        "Some interesting learning pages are\n",
        "* [Roger Dudler's git guide](https://rogerdudler.github.io/git-guide/index.html)\n",
        "* [Intro videos for beginners](https://www.git-tower.com/learn/git/videos/), use the CLI version of the videos.\n",
        "\n",
        "## Jupyter Notebook\n",
        "You're here, aren't you? So you already managed to see a notebook, and when we come to the action part, you will get interactive too. Let's stick to the headline \"documentation and coding environment\" as the mental model why we are here.\n",
        "\n",
        "No worries, we don't code yet. If you are on a Colab environment, let's just use a little predefined notebook integration to insert a codeblock semi-automatically. Click the folder on the left toolbar, then select the folder with the google drive symbol. **Do not** accept the access options. \n",
        "\n",
        "![gdrive-image](https://github.com/selfscrum/hello-ai/blob/main/images/gdrive.png?raw=1)\n",
        "\n",
        "This will cause Colab to add a code block below the currently selected one.\n",
        "\n",
        "![gdrive-block-image](https://github.com/selfscrum/hello-ai/blob/main/images/gdrive-block.png?raw=1)\n",
        "\n",
        "If you hover over the area between the square brackets, a play symbol appears. Click on it, and confirm all the warnings and acceptance screens. After some seconds, the code block (this is what it actually is) is executed successfully, indicated by a green checkmark. You know now that this block has run in this session. \n",
        "\n",
        "![gdrive-success-image](https://github.com/selfscrum/hello-ai/blob/main/images/gdrive-success.png?raw=1)\n",
        "\n",
        "If you refresh now the folder view in the left panel, you see the mounted drive folder which points to your private Google Drive space. This means you can access all files in Google Drive from within the Notebook. You might want to use it for session results, and data and model uploads. All assets that are meant to persist the session, should be stored directly in the notebook or as files in Github."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkg475CCwYbq"
      },
      "source": [
        "\n",
        "## Python\n",
        "\n",
        "I am not a professional developer and know Python only from occasional small coding sessions. What I see in most notebooks is some glue code or a sequence of setup steps for the technology we are going to use. So, if you have a rough understanding what coding with Python is, this won't hurt. If all goes well, you do not need to jump into the code but just have to start it - this is the beauty of Jupyter Notebooks, which can guide you through an interactive session without jumping in every tarpit.\n",
        "\n",
        "But if something goes wrong, you might get some error messages. It is surely beneficial if you can roughly interpret them, or check answers from Google to fix the problem.\n",
        "\n",
        "## Markdown\n",
        "\n",
        "You should be familiar with the markdown notation since this is how Jupyter Notebook texts are written. You find this supported in many tools like Github, Notion, too name some. It is easy and compelling and relieves you from the \"Learn MS Word\" burden. See [Markdown Guide](https://www.markdownguide.org/)\n",
        "\n",
        "## Image manipulation\n",
        "\n",
        "If you are interested in image processing, you might need some processing tools since current AI has quite some prerequisites about image formats etc. You can use any desktop app of your choice, or you can use web services like [Birme](https://birme.net) to support your batch workflow.\n",
        "\n",
        "An increasingly interesting combination is the creation of quick low-scale images by the generation model and an AI-based scale-up app that creates a high-res, high-quality image afterwards.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8iqqCuWH3d9"
      },
      "source": [
        "# Find your Heros\n",
        "\n",
        "Learning alone is not how you get up to speed. Find a learning group to discuss your targets, your plans, your issues, and to celebrate your successes. This could be someone from your surroundings, or maybe you find a discord forum around one of the tools we are going to see.\n",
        "\n",
        "At least you should tune into some youtube videos to get some basic conceptual understanding. As always for a new topic, it's hard to know what you are looking for, so you have to try out some channels to find the proper ones that fit your needs and support you best.\n",
        "\n",
        "I learned from (in order of appearance on my radar)\n",
        "* [Kris Kashtanova](https://www.kris.art/), an early adoptor of image creation on Midjourney.\n",
        "* [Sebastian Kamph](https://www.youtube.com/@sebastiankamph) about Stable Diffusion, deforum and Automatic1111.\n",
        "* [Amelia Player aka PromptMuse](https://www.youtube.com/@promptmuse) about various image and video processing workflows.\n",
        "* [David Shapiro](https://www.youtube.com/@DavidShapiroAutomator) GPT3 and ChatGPT experiments with Python. He is always \"5 minutes ahead\" of you, so if you like to follow searchers, this is the one for you.\n",
        "* [Olivio Sarikas](https://www.youtube.com/@OlivioSarikas) for prompt engineering details for imaging.\n",
        "* [Maggie Appleton](https://maggieappleton.com/forest-talk), Designer and anthropologist with some impressive and well-researched essays about the topic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTj9i_BzjvmN"
      },
      "source": [
        "# Start experimenting\n",
        "\n",
        "What are your most urgent questions? how do you enter the scene? This is hard to answer generally since everyone comes from a different path and has different knowledge.\n",
        "\n",
        "If you are completely new to AI and coding, you might want to start easy with\n",
        "* [ChatGPT](https://chat.openai.com/). Very low entry barrier, you get a chat window and can start talking to the ai without any background knowledge.\n",
        "* [Midjourney](https://midjourney.com/). Image generation site. To use it, you need to have a Discord account, which is for people new to the scene something like \"Teams on steroids\". It has its roots in the gamer scene but is meanwhile a popular community platform for many new initiatives. Follow the guidelines there to sign up, then \"Join the Beta\" on Midjourney."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82Ix-cma5pld"
      },
      "source": [
        "# Advanced Experiments\n",
        "\n",
        "> The current cambrian explosion of advances in the AI ecosystem is breathtaking. New tools are released by the hour, and many libraries I use here are under steady development. Some breaks might occur. I try to keep everything somewhat up to date. If you come across an error please let me know by creating an issue [here](https://github.com/selfscrum/hello-ai/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n6SheTlRmI9"
      },
      "source": [
        "## Build a Knowledge Hub Around a GPT Model\n",
        "As impressive GPT is, it has one big shortcoming:\n",
        "\n",
        "---\n",
        "> **You can't infuse new knowledge easily**\n",
        "---\n",
        "\n",
        "This might be surprising, isn't this what a Large Language Model (LLM) is all about? Yes and no. Training of an LLM is a long-during expensive task which requires vast amounts of texts. A typical GPT user cannot afford these resources, so that is a limiting factor. In addition, training takes a lot of time, so scenarios where your knowledge is varying more often (e.g. look at a typical IT curriculum, or even worse, at a marketing customer pipeline), you are at a loss with that approach.\n",
        "\n",
        "Another strategy is to built semantic indices of your current knowledge sets (also known as **vectors**, since each **chunk** (piece of knowledge) can be mapped to a mathematical multidemensional vector representing the information in the knowledge piece. If you then ask something, this question is vectorized as well and the vector store can easily find related answers by comparing the vectors. These answers can then be passed into GPT to phrase a good response to your original request.\n",
        "\n",
        "![vectors](https://github.com/selfscrum/hello-ai/blob/main/images/vectors.png?raw=1)\n",
        "\n",
        "That's what we are going to build here. A new open source project named LlamaIndex is supporting just that, and, even better, has already a lot of connectors to typical knowledge stores, like databases, Slack, Notion etc. Let's see how this works out!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYR9IKCLMoVh"
      },
      "source": [
        "### Install LlamaIndex and do a Quick Starter Tour\n",
        "\n",
        "We can follow the tutorial from [here](https://gpt-index.readthedocs.io/en/latest/getting_started/installation.html):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr_pcGENUwQn"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMWZkGn-g_E0"
      },
      "source": [
        "I store my openapi key on the private part of My Google Drive. This removes the need to edit a public notebook every time. The file must contain only the key (no newline!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gomXEMJCVWYP"
      },
      "outputs": [],
      "source": [
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "api_key = open_file('/content/drive/MyDrive/llama-openapikey.txt')\n",
        "%set_env OPENAI_API_KEY=$api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXbg-xPMW_1m"
      },
      "source": [
        "Now you can install the current release of LlamaIndex (they just recently renamed, still sometimes referred to as `gpt_index`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REuJM75AXNi3"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/jerryjliu/gpt_index.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLu3_8J5b4wu"
      },
      "source": [
        "Start the code of an example to check whether the service is running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEfG1DvSY0Dk"
      },
      "outputs": [],
      "source": [
        "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "%cd /content/gpt_index/examples/paul_graham_essay/\n",
        "\n",
        "documents = SimpleDirectoryReader('data').load_data()\n",
        "index = GPTVectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuX3r3pRfnyb"
      },
      "source": [
        "Now you can query the essay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV6pbFP0co4Z"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXPPFDH15_BX"
      },
      "source": [
        "### Process a book to get an online query engine\n",
        "\n",
        "In the example above we just read some 300 statements from that essay, and were able to give some satisfying answers.\n",
        "\n",
        "Let's now increase the stakes a little. I am going to import a PDF ebook (\"Practical Process Automation\" of Bernd Ruecker, about 300 pages, 18 MB) in a simple vector index - this is the general purpose index you can use for document retrieval, as we did before.\n",
        "\n",
        "You can do that to if you have the PDF, it was available free as a sponsored download for some time (but of course you can use any other text-based PDF as well. Make sure it's not too short.)\n",
        "\n",
        "I upload the document to my Google Drive and load it from there into the index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpYCx-9O8kZc"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from llama_index import download_loader\n",
        "from llama_index import GPTVectorStoreIndex\n",
        "\n",
        "PDFReader = download_loader(\"PDFReader\")\n",
        "\n",
        "loader = PDFReader()\n",
        "pdfdocuments = loader.load_data(file=Path('/content/drive/MyDrive/pdfs/PracticalProcessAutomation_Camunda.pdf'))\n",
        "pdfindex = GPTVectorStoreIndex.from_documents(pdfdocuments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ODaNXrN8_L3"
      },
      "source": [
        "That was quite quick! Now we can query the book's knowledge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mE97HN_8_mG"
      },
      "outputs": [],
      "source": [
        "query_engine = pdfindex.as_query_engine()\n",
        "response = query_engine.query(\"Should we use Powerpoint for Process Modeling? Please name better alternatives.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGGyMZwtMyp4"
      },
      "source": [
        "### Process a second book \n",
        "\n",
        "Can we increase our knowledge base? For sure! We could just load another document into the index. I choose the \"Data Mesh\" book of Zhamak Dehghani (another sponsored copy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i32X06UHPDPI"
      },
      "outputs": [],
      "source": [
        "pdfdocs2 = loader.load_data(file=Path('/content/drive/MyDrive/pdfs/DataMesh.pdf'))\n",
        "for doc in pdfdocs2:\n",
        "  pdfindex.insert(doc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7vgR4V2PcC1"
      },
      "source": [
        "This takes a little longer, the book has nearly 400 pages and is 55 MB in size. After a minute we are ready, and the same query as above might yield better results, especially when we ask now about topics that belong to both books, e.g. \"How can we use Practical Process Automation to implement Data Mesh?\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx39oARHNWtq"
      },
      "source": [
        "This works all pretty well âœ¨, but we just scratched the surface. \n",
        "\n",
        "What we technically did now is loading both books (chopped into small chunks that the language model can process) into a list of vectors that we can search and pass on to a summarized answer. LlamaIndex does this for us in a nice and easy way, while hiding the complexities of the workflow. The structure is still simple though, and we have lots of option unrevealed.\n",
        "\n",
        "![llamaindexoptions](https://github.com/selfscrum/hello-ai/blob/main/images/llamaindex-options.png?raw=1)\n",
        "\n",
        "So, we must decide how we can improve our knowledge base next:\n",
        "\n",
        "* Increase Token Size, or make it variable, to allow longer answers,\n",
        "* Allow other language models than the default, or provide parameter tuning tweaks,\n",
        "* Use another index structure to support hierarchical content in a better way,\n",
        "* add more content connectors to allow more formats to be processed,\n",
        "* build advanced index chains to get more semantical awareness into your system.\n",
        "\n",
        "Stay patient! We will cover it all âš¡ when we goo deeper.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Chaining\n",
        "\n",
        "Prompt Chaining is a method that tries to avoid a lot of the current LLM weaknesses - no recent knowledge, no query results, no maths and so on. The concept is simple and compelling - a reasoning loop combined with external tools like a search engine, a Wolfram engine or a self-written command creates output which then is taken again as input for the next steps.\n",
        "\n",
        "You could consider it to be a self-writing workflow. A good example is [AgentGPT](https://agentgpt.reworkd.ai/de) (you need an OpenAI API Key), or the [Langchain Library](https://python.langchain.com/en/latest/) we are going to use in a minute.\n",
        "\n",
        "Prompt Chain image, taken from Maggie Appleton's Digital Garden:\n",
        "![Prompt Chaining, taken from Maggie Appleton's Digital Garden](https://maggieappleton.com/images/posts/forest-talk/dft_54.jpeg)\n",
        "\n"
      ],
      "metadata": {
        "id": "SImn0AA2kinK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First-Time Preparations \n",
        "\n",
        "If you didn't try the Knowledge Hub experiments above, you have to run the commands in this section. Otherwhise you can skip this block.\n",
        "\n",
        "First, install the foundational libraries."
      ],
      "metadata": {
        "id": "gdhtxiN6_R6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "mbBV8efrAQSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then you will need to store your OpenAI access key in the runtime environment."
      ],
      "metadata": {
        "id": "zM7Pxet7BlAP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z9uvDj4SBqEm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6w3Ls1FwJsLPo/I7iosy/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}