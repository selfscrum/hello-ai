{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/msF9VRJuLMidgCzNjMVG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selfscrum/hello-ai/blob/main/learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up a Hosting Provider\n",
        "\n",
        "If you have worked with Cloud providers, you know the setup of virtual machines. While for classic projects, a virtual machine is rather a convenience (quick setup, automated installation, secured environment etc.), it becomes a \"must\" for experiments with AI. Models, data, and processing needs grow so quick that maintaining your own setup is not feasible any longer - at least until you leave learning mode and decide to build your own AI factory 😅.\n",
        "\n",
        "For first steps, [Google Colab](https://colab.research.google.com/) is a good and easy to use option:\n",
        "* Free for initial steps.\n",
        "* Integrated with your Google Account and Drive, so you have a project store already.\n",
        "* Integrated with Github, so you can easily maintain the development of your notebooks in an orderly fashion.\n",
        "* Paid upgrades possible if you need more.\n",
        "* Local runtime of Jupyter possible if you already have resources available ([Setup Info ](https://research.google.com/colaboratory/local-runtimes.html), not yet tried).\n",
        "\n",
        "Especially in the free environment, Colab has some performance and quality issues. You will learn pretty quick about broken tasks because your (virtual) hardware is not sufficient. So if you want to upgrade to Colab Pro or move to a more specialized provider, feel free to do so. I tried some few, but are not yet able to compare them systematically since I basically used only beginner's feature sets.\n",
        "\n",
        "* [RunPod](https://www.runpod.io/) - GPU Cloud with pre-setup environments\n",
        "* [Paperspace](https://paperspace.com) - Notebooks, GPU, Deployment Services\n",
        "* [HuggingFace](https://huggingface.co/) - Home of the Open Source Models, Development and Deployment ecosystem (you will need here an account in any case if you want to use one of the open models like Stable Diffusion or GPT-J).\n",
        "\n",
        "---\n",
        "> **Keep an eye on where you commit to usage fees, there are many tools out there that require a funding source. Even if it is only some cents for initial experiments, consumption can get out of hand easily.**\n",
        "---"
      ],
      "metadata": {
        "id": "VjbM5InfQjTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Know Your Tools\n",
        "\n",
        "It's great that ChatGPT can write now software code for you, but what do you do with it? Today's tool chain maturity still requires that you integrate partial results into an end-to-end workstream. So you should at least roughly know what you are doing with the individual components.\n",
        "\n",
        "For developers this might be familiar turf to some extent, so you can quickly flip through this block. For everyone else, this chapter is not necessarily a roadblock before you can jump into AI joys, but it can't hurt to make yourself familiar with these concepts before or in parallel to the AI learning, depending how you learn best.\n",
        "\n",
        "## Git\n",
        "git is the central repository for developer articats and platforms like Github have evolved to a complete tech ecosystem. I don't want to write just another git manual, there is plenty out there. Checkout some places to learn about the basic lifecycle, this is enough for our purposes.\n",
        "\n",
        "Some interesting learning pages are\n",
        "* [Roger Dudler's git guide](https://rogerdudler.github.io/git-guide/index.html)\n",
        "* [Intro videos for beginners](https://www.git-tower.com/learn/git/videos/), use the CLI version of the videos.\n",
        "\n",
        "## Jupyter Notebook\n",
        "You're here, aren't you? So you already managed to see a notebook, and when we come to the action part, you will get interactive too. Let's stick to the headline \"documentation and coding environment\" as the mental model why we are here.\n",
        "\n",
        "No worries, we don't code yet. If you are on a Colab environment, let's just use a little predefined notebook integration to insert a codeblock semi-automatically. Click the folder on the left toolbar, then select the folder with the google drive symbol. **Do not** accept the access options. \n",
        "\n",
        "![gdrive-image](https://github.com/selfscrum/hello-ai/blob/main/images/gdrive.png?raw=1)\n",
        "\n",
        "This will cause Colab to add a code block below the currently selected one.\n",
        "\n",
        "![gdrive-block-image](https://github.com/selfscrum/hello-ai/blob/main/images/gdrive-block.png?raw=1)\n",
        "\n",
        "If you hover over the area between the square brackets, a play symbol appears. Click on it, and confirm all the warnings and acceptance screens. After some seconds, the code block (this is what it actually is) is executed successfully, indicated by a green checkmark. You know now that this block has run in this session. \n",
        "\n",
        "![gdrive-success-image](https://github.com/selfscrum/hello-ai/blob/main/images/gdrive-success.png?raw=1)\n",
        "\n",
        "If you refresh now the folder view in the left panel, you see the mounted drive folder which points to your private Google Drive space. This means you can access all files in Google Drive from within the Notebook. You might want to use it for session results, and data and model uploads. All assets that are meant to persist the session, should be stored directly in the notebook or as files in Github."
      ],
      "metadata": {
        "id": "XLk0C-xbWdn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Python\n",
        "\n",
        "I am not a professional developer and know Python only from occasional small coding sessions. What I see in most notebooks is some glue code or a sequence of setup steps for the technology we are going to use. So, if you have a rough understanding what coding with Python is, this won't hurt. If all goes well, you do not need to jump into the code but just have to start it - this is the beauty of Jupyter Notebooks, which can guide you through an interactive session without jumping in every tarpit.\n",
        "\n",
        "But if something goes wrong, you might get some error messages. It is surely beneficial if you can roughly interpret them, or check answers from Google to fix the problem.\n",
        "\n",
        "## Markdown\n",
        "\n",
        "You should be familiar with the markdown notation since this is how Jupyter Notebook texts are written. You find this supported in many tools like Github, Notion, too name some. It is easy and compelling and relieves you from the \"Learn MS Word\" burden. See [Markdown Guide](https://www.markdownguide.org/)\n",
        "\n",
        "## Image manipulation\n",
        "\n",
        "If you are interested in image processing, you might need some processing tools since current AI has quite some prerequisites about image formats etc. You can use any desktop app of your choice, or you can use web services like [Birme](https://birme.net) to support your batch workflow.\n"
      ],
      "metadata": {
        "id": "Gkg475CCwYbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find your Heros\n",
        "\n",
        "Learning alone is not how you get up to speed. Find a learning group to discuss your targets, your plans, your issues, and to celebrate your successes. This could be someone from your surroundings, or maybe you find a discord forum around one of the tools we are going to see.\n",
        "\n",
        "At least you should tune into some youtube videos to get some basic conceptual understanding. As always for a new topic, it's hard to know what you are looking for, so you have to try out some channels to find the proper ones that fit your needs and support you best.\n",
        "\n",
        "I learned from (in order of appearance on my radar)\n",
        "* [Kris Kashtanova](https://www.kris.art/), an early adoptor of image creation on Midjourney\n",
        "* [Sebastian Kamph](https://www.youtube.com/@sebastiankamph) about Stable Diffusion, deforum and Automatic1111\n",
        "* [Amelia Player aka PromptMuse](https://www.youtube.com/@promptmuse) about various image and video processing workflows\n",
        "* [David Shapiro](https://www.youtube.com/@DavidShapiroAutomator) GPT3 and ChatGPT experiments with Python. He is always \"5 minutes ahead\" of you, so if you like to follow searchers, this is the one for you.\n",
        "* [Olivio Sarikas](https://www.youtube.com/@OlivioSarikas) for prompt engineering details for imaging"
      ],
      "metadata": {
        "id": "J8iqqCuWH3d9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start experimenting\n",
        "\n",
        "What are your most urgent questions? how do you enter the scene? This is hard to answer generally since everyone comes from a different path and has different knowledge.\n",
        "\n",
        "If you are completely new to AI and coding, you might want to start easy with\n",
        "* [ChatGPT](https://chat.openai.com/). Very low entry barrier, you get a chat window and can start talking to the ai without any background knowledge.\n",
        "* [Midjourney](https://midjourney.com/). Image generation site. To use it, you need to have a Discord account, which is for people new to the scene something like \"Teams on steroids\". It has its roots in the gamer scene but is meanwhile a popular community platform for many new initiatives. Follow the guidelines there to sign up, then \"Join the Beta\" on Midjourney."
      ],
      "metadata": {
        "id": "gTj9i_BzjvmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Experiments\n",
        "\n",
        "## Build a Knowledge Hub Around a GPT Model\n",
        "As impressive GPT is, it has one big shortcoming:\n",
        "\n",
        "---\n",
        "> **You can't infuse new knowledge easily**\n",
        "---\n",
        "\n",
        "This might be surprising, isn't this what a Large Language Model (LLM) is all about? Yes and no. Training of an LLM is a long-during expensive task which requires vast amounts of texts. A typical GPT user cannot afford these resources, so that is a limiting factor. In addition, training takes a lot of time, so scenarios where your knowledge is varying more often (e.g. look at a typical IT curriculum, or even worse, at a marketing customer pipeline), you are at a loss with that approach.\n",
        "\n",
        "Another strategy is to built semantic indices of your current knowledge sets (also known as **vectors**, since each **chunk** (piece of knowledge) can be mapped to a mathematical multidemensional vector representing the information in the knowledge piece. If you then ask something, this question is vectorized as well and the vector store can easily find related answers by comparing the vectors. These answers can then be passed into GPT to phrase a good response to your original request.\n",
        "\n",
        "That's what we are going to build here. A new open source project named LlamaIndex is supporting just that, and, even better, has already a lot of connectors to typical knowledge stores, like databases, Slack, Notion etc. Let's see how this works out!\n",
        "\n",
        "### Install LlamaIndex\n",
        "\n",
        "We can follow the tutorial from [here](https://gpt-index.readthedocs.io/en/latest/getting_started/installation.html):\n"
      ],
      "metadata": {
        "id": "1n6SheTlRmI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr_pcGENUwQn",
        "outputId": "ec44bb83-d4bc-4c2e-d029-db18c18bd45c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.4.21.tar.gz (126 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.101-py3-none-any.whl (344 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.0/344.0 KB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=0.26.4\n",
            "  Downloading openai-0.27.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses_json\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from llama-index) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from llama-index) (1.22.4)\n",
            "Collecting tenacity<8.2.0\n",
            "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from llama-index) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai>=0.26.4->llama-index) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai>=0.26.4->llama-index) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai>=0.26.4->llama-index) (3.8.4)\n",
            "Collecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses_json->llama-index) (3.19.0)\n",
            "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain->llama-index) (1.4.46)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.8/dist-packages (from langchain->llama-index) (6.0)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain->llama-index) (1.10.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->llama-index) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->llama-index) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->llama-index) (2022.6.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->llama-index) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->llama-index) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers->llama-index) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (6.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers->llama-index) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->llama-index) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai>=0.26.4->llama-index) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai>=0.26.4->llama-index) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai>=0.26.4->llama-index) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai>=0.26.4->llama-index) (4.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy<2,>=1->langchain->llama-index) (2.0.2)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: llama-index\n",
            "  Building wheel for llama-index (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-index: filename=llama_index-0.4.21-py3-none-any.whl size=186935 sha256=17fa960149571bc8ec960af3208baccd570dfecf4ae797650c479bad69451957\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/42/36/3c9037bf75363b792c5a6bd11171b915dd3768f6c9c732d22a\n",
            "Successfully built llama-index\n",
            "Installing collected packages: tokenizers, tenacity, mypy-extensions, typing-inspect, marshmallow-enum, huggingface-hub, transformers, openai, dataclasses_json, langchain, llama-index\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.2.1\n",
            "    Uninstalling tenacity-8.2.1:\n",
            "      Successfully uninstalled tenacity-8.2.1\n",
            "Successfully installed dataclasses_json-0.5.7 huggingface-hub-0.12.1 langchain-0.0.101 llama-index-0.4.21 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openai-0.27.0 tenacity-8.1.0 tokenizers-0.13.2 transformers-4.26.1 typing-inspect-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I store my openapi key on the private part of My Google Drive. This removes the need to edit a public notebook every time. The file must contain only the key (no newline!)"
      ],
      "metadata": {
        "id": "XMWZkGn-g_E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "api_key = open_file('/content/drive/MyDrive/llama-openapikey.txt')\n",
        "%set_env OPENAI_API_KEY=$api_key"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gomXEMJCVWYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can install the current release of LlamaIndex (they just recently renamed, still sometimes referred to as `gpt_index`)"
      ],
      "metadata": {
        "id": "JXbg-xPMW_1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jerryjliu/gpt_index.git"
      ],
      "metadata": {
        "id": "REuJM75AXNi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start the code of an example to check whether the service is running."
      ],
      "metadata": {
        "id": "oLu3_8J5b4wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader\n",
        "\n",
        "%cd /content/gpt_index/examples/paul_graham_essay/\n",
        "\n",
        "documents = SimpleDirectoryReader('data').load_data()\n",
        "index = GPTSimpleVectorIndex(documents)\n"
      ],
      "metadata": {
        "id": "nEfG1DvSY0Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can query the essay."
      ],
      "metadata": {
        "id": "XuX3r3pRfnyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = index.query(\"What did the author do growing up?\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "bV6pbFP0co4Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}